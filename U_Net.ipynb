{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U-Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3S-J2TMI8M4"
      },
      "source": [
        "'''\n",
        "U-Net Implementation\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GA5l4mnZn03B"
      },
      "source": [
        "## DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi3BYfPQvnvd"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms, utils\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import os\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%load_ext autoreload\n",
        "\n",
        "%autoreload 2\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "\n",
        "\n",
        "from torch.nn import Conv2d as Conv2D\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Upsample\n",
        "\n",
        "import cv2\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1EtK9dZH4pq"
      },
      "source": [
        "!gdown --id 1opMhHAiMJVdD0eYAJEcuHZgTscgFBCpj\n",
        "!gdown --id 1uVs0yvi-HRj0yyez9MbnGwk_EsCHDLzl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQwEuQi9U92t"
      },
      "source": [
        "%mkdir Dataset\n",
        "%mkdir Dataset/2d_images\n",
        "%mkdir Dataset/2d_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bhf6fHWlURN6"
      },
      "source": [
        "\n",
        "!unzip -q 2d_images.zip.zip \n",
        "!unzip -q 2d_images.zip -d Dataset/2d_images\n",
        "\n",
        "!unzip -q 2d_masks.zip.zip \n",
        "!unzip -q 2d_masks.zip -d Dataset/2d_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDjVbTzKV9JI"
      },
      "source": [
        "!rm -rf 2d_images.zip.zip\n",
        "!rm -rf 2d_images.zip\n",
        "\n",
        "!rm -rf 2d_masks.zip.zip\n",
        "!rm -rf 2d_masks.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr7lj5Hcyabk"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ukp9r5W9eZC"
      },
      "source": [
        "class CT_Data(Dataset):\n",
        "\n",
        "    def __init__(self, csv_file, root_dir):\n",
        "\n",
        "        self.image_frame = pd.read_csv(csv_file, skiprows=1)\n",
        "        self.root_dir = root_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 0])\n",
        "        mask_name = os.path.join(self.root_dir, self.image_frame.iloc[idx, 1])\n",
        "        image = cv2.imread(img_name, 0)\n",
        "        image = cv2.resize(image,(32, 32))\n",
        "        image = image.reshape((1, 32, 32))\n",
        "        mask = cv2.imread(mask_name, 0)\n",
        "        mask = cv2.resize(mask, (32, 32))\n",
        "        mask = mask.reshape((1, 32, 32))\n",
        "        sample = {'image': image, 'mask': mask}\n",
        "        return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4akgB1MbygYG"
      },
      "source": [
        "img_dir = \"Dataset/2d_images/\"\n",
        "msk_dir = \"Dataset/2d_masks/\"\n",
        "with open('Dataset/Dataset.csv', 'w') as csv_file:\n",
        "    writer = csv.writer(csv_file)\n",
        "    writer.writerow([\"filename\", \"mask\"])\n",
        "    for p in os.listdir(img_dir):\n",
        "        image_path = os.path.join(img_dir, p)\n",
        "        mask_path = os.path.join(msk_dir, p)\n",
        "        writer.writerow([image_path, mask_path])\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"Dataset/Dataset.csv\")\n",
        "data = data.iloc[np.random.permutation(len(data))]\n",
        "partition = int(len(data)*0.7)\n",
        "train, validation = data[:partition], data[partition:]\n",
        "train.to_csv(\"Dataset/Train.csv\", index=False)\n",
        "validation.to_csv(\"Dataset/Validation.csv\", index=False)\n",
        "\n",
        "train_dataset = CT_Data(csv_file='Dataset/Train.csv', root_dir='/content')\n",
        "val_dataset = CT_Data(csv_file='Dataset/Validation.csv', root_dir='/content')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=37, shuffle=True, num_workers=4)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=20, shuffle=True, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPXR8tEIyhyw"
      },
      "source": [
        "## U-Net Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpsspcUc9AIY"
      },
      "source": [
        "\n",
        "class Up(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(Up, self).__init__()\n",
        "        ###########################################\n",
        "        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "        self.conv = nn.Sequential(\n",
        "            Conv2D(\n",
        "                  channel_in,\n",
        "                   channel_out,\n",
        "                   kernel_size=3,\n",
        "                   padding=1),\n",
        "                   nn.BatchNorm2d(channel_out),\n",
        "                   nn.ReLU(inplace=True)\n",
        "        )\n",
        "        ###########################################\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        ###########################################\n",
        "        x1 = self.upsample(x1)\n",
        "        diff_x = x1.size()[2] - x2.size()[2]\n",
        "        diff_y = x1.size()[3] - x2.size()[3]\n",
        "        # Padding \n",
        "        x2 = F.pad(x2, (diff_x // 2, int(diff_x / 2),\n",
        "                        diff_y // 2, int(diff_y / 2)))\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        x = self.conv(x)\n",
        "        return x        \n",
        "        ###########################################\n",
        "        \n",
        "class Down(nn.Module):\n",
        "    def __init__(self, channel_in, channel_out):\n",
        "        super(Down, self).__init__()\n",
        "        ###########################################\n",
        "        self.conv = nn.Sequential(\n",
        "            Conv2D(\n",
        "                channel_in,\n",
        "                channel_out,\n",
        "                kernel_size = 3,\n",
        "                padding = 1),\n",
        "                nn.BatchNorm2d(channel_out),\n",
        "                nn.ReLU(inplace=True)\n",
        "        )\n",
        "        ###########################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        ###########################################\n",
        "        x = F.max_pool2d(x,2)\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "        ###########################################\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, channel_in, classes):\n",
        "        super(UNet, self).__init__()\n",
        "        ###########################################\n",
        "        self.conv1 = nn.Sequential(\n",
        "            Conv2D(channel_in, 8, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(8),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.down1 = Down(8, 16)\n",
        "        self.down2 = Down(16, 32)\n",
        "        self.down3 = Down(32, 32)\n",
        "        self.up1 = Up(64, 16)\n",
        "        self.up2 = Up(32, 8)\n",
        "        self.up3 = Up(16, 4)\n",
        "        self.conv2 = nn.Conv2d(4, classes, kernel_size = 1)\n",
        "        ###########################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        ###########################################\n",
        "        x1 = self.conv1(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x = self.up1(x4, x3)\n",
        "        x = self.up2(x, x2)\n",
        "        x = self.up3(x, x1)\n",
        "        x = self.conv2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        return x\n",
        "        ###########################################\n",
        "\n",
        "def weights_init(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        init.xavier_uniform(m.weight, gain=numpy.sqrt(2.0))\n",
        "        init.constant(m.bias, 0.1)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IHuR2DYy7P9"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdlN7pmGjd6g"
      },
      "source": [
        "def IoU(output, target):\n",
        "    smooth = 1e-5\n",
        "    oss = output > 0.5\n",
        "    tss = target > 0.5\n",
        "    intersection = (oss & tss).sum(axis=[1, 2, 3])\n",
        "    union = (oss | tss).sum(axis=[1, 2, 3])\n",
        "    IoU = ((intersection + smooth) / (union + smooth)).mean()\n",
        "    return IoU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgYtlFne9U3k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bf5d81-423a-445f-aa37-febbb0e4eea5"
      },
      "source": [
        "\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "freq = 1\n",
        "model = UNet(1, 1)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "def train(model, epoch):\n",
        "    ###########################################\n",
        "    model.train()\n",
        "    correct = 0\n",
        "    ###########################################\n",
        "    for batch_idx, data in enumerate(train_dataloader):\n",
        "        ###########################################\n",
        "        data, target = Variable(data[\"image\"]), Variable(data[\"mask\"])\n",
        "        # Normalize Data\n",
        "        target = (target-torch.min(target))/(torch.max(target)-torch.min(target))\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(data.float())\n",
        "        loss = criterion(output.float(), target.float())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ###########################################\n",
        "        if batch_idx % freq == 0:\n",
        "            batch_percent = 100. * batch_idx / len(train_dataloader)\n",
        "            print(f'Epoch number:{epoch} '  \n",
        "                  f'({batch_percent}%)\\tLoss:{loss.data:.3f}'\n",
        "                 )\n",
        "        ###########################################       \n",
        "            \n",
        "            \n",
        "\n",
        "def test(model):\n",
        "    ###########################################\n",
        "    model.eval()\n",
        "    ###########################################\n",
        "    loss = iou = 0.\n",
        "    for data in val_dataloader:\n",
        "        ###########################################\n",
        "        data, target = Variable(data['image'], volatile=True), Variable(data['mask'])\n",
        "        output = model(data.float())\n",
        "        # Normalize Data\n",
        "        target = (target-torch.min(target))/(torch.max(target)-torch.min(target))\n",
        "        loss += criterion(output.float(), target.float()).data \n",
        "        iou += IoU(output, target)   \n",
        "    loss /= len(val_dataloader)\n",
        "    iou /= len(val_dataloader)\n",
        "    print(f'Average loss:{loss:.3f}\\nIoU:{iou:.3f}\\n')\n",
        "    ###########################################\n",
        "\n",
        "Num_of_eopchs = 25\n",
        "\n",
        "for epoch in range(1, Num_of_eopchs):\n",
        "    train(model, epoch)\n",
        "    test(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch number:1 (0.0%)\tLoss:0.763\n",
            "Epoch number:1 (20.0%)\tLoss:0.629\n",
            "Epoch number:1 (40.0%)\tLoss:0.569\n",
            "Epoch number:1 (60.0%)\tLoss:0.547\n",
            "Epoch number:1 (80.0%)\tLoss:0.530\n",
            "Average loss:2.424\n",
            "IoU:0.242\n",
            "\n",
            "Epoch number:2 (0.0%)\tLoss:0.522\n",
            "Epoch number:2 (20.0%)\tLoss:0.511\n",
            "Epoch number:2 (40.0%)\tLoss:0.493\n",
            "Epoch number:2 (60.0%)\tLoss:0.479\n",
            "Epoch number:2 (80.0%)\tLoss:0.463\n",
            "Average loss:2.818\n",
            "IoU:0.246\n",
            "\n",
            "Epoch number:3 (0.0%)\tLoss:0.458\n",
            "Epoch number:3 (20.0%)\tLoss:0.450\n",
            "Epoch number:3 (40.0%)\tLoss:0.435\n",
            "Epoch number:3 (60.0%)\tLoss:0.423\n",
            "Epoch number:3 (80.0%)\tLoss:0.410\n",
            "Average loss:1.412\n",
            "IoU:0.267\n",
            "\n",
            "Epoch number:4 (0.0%)\tLoss:0.398\n",
            "Epoch number:4 (20.0%)\tLoss:0.388\n",
            "Epoch number:4 (40.0%)\tLoss:0.384\n",
            "Epoch number:4 (60.0%)\tLoss:0.366\n",
            "Epoch number:4 (80.0%)\tLoss:0.360\n",
            "Average loss:0.668\n",
            "IoU:0.393\n",
            "\n",
            "Epoch number:5 (0.0%)\tLoss:0.344\n",
            "Epoch number:5 (20.0%)\tLoss:0.333\n",
            "Epoch number:5 (40.0%)\tLoss:0.327\n",
            "Epoch number:5 (60.0%)\tLoss:0.315\n",
            "Epoch number:5 (80.0%)\tLoss:0.315\n",
            "Average loss:0.357\n",
            "IoU:0.722\n",
            "\n",
            "Epoch number:6 (0.0%)\tLoss:0.296\n",
            "Epoch number:6 (20.0%)\tLoss:0.292\n",
            "Epoch number:6 (40.0%)\tLoss:0.277\n",
            "Epoch number:6 (60.0%)\tLoss:0.276\n",
            "Epoch number:6 (80.0%)\tLoss:0.259\n",
            "Average loss:0.300\n",
            "IoU:0.797\n",
            "\n",
            "Epoch number:7 (0.0%)\tLoss:0.259\n",
            "Epoch number:7 (20.0%)\tLoss:0.245\n",
            "Epoch number:7 (40.0%)\tLoss:0.243\n",
            "Epoch number:7 (60.0%)\tLoss:0.227\n",
            "Epoch number:7 (80.0%)\tLoss:0.219\n",
            "Average loss:0.259\n",
            "IoU:0.815\n",
            "\n",
            "Epoch number:8 (0.0%)\tLoss:0.213\n",
            "Epoch number:8 (20.0%)\tLoss:0.207\n",
            "Epoch number:8 (40.0%)\tLoss:0.207\n",
            "Epoch number:8 (60.0%)\tLoss:0.209\n",
            "Epoch number:8 (80.0%)\tLoss:0.187\n",
            "Average loss:0.218\n",
            "IoU:0.853\n",
            "\n",
            "Epoch number:9 (0.0%)\tLoss:0.203\n",
            "Epoch number:9 (20.0%)\tLoss:0.177\n",
            "Epoch number:9 (40.0%)\tLoss:0.171\n",
            "Epoch number:9 (60.0%)\tLoss:0.166\n",
            "Epoch number:9 (80.0%)\tLoss:0.160\n",
            "Average loss:0.194\n",
            "IoU:0.862\n",
            "\n",
            "Epoch number:10 (0.0%)\tLoss:0.155\n",
            "Epoch number:10 (20.0%)\tLoss:0.152\n",
            "Epoch number:10 (40.0%)\tLoss:0.162\n",
            "Epoch number:10 (60.0%)\tLoss:0.153\n",
            "Epoch number:10 (80.0%)\tLoss:0.141\n",
            "Average loss:0.179\n",
            "IoU:0.865\n",
            "\n",
            "Epoch number:11 (0.0%)\tLoss:0.147\n",
            "Epoch number:11 (20.0%)\tLoss:0.143\n",
            "Epoch number:11 (40.0%)\tLoss:0.133\n",
            "Epoch number:11 (60.0%)\tLoss:0.124\n",
            "Epoch number:11 (80.0%)\tLoss:0.123\n",
            "Average loss:0.148\n",
            "IoU:0.883\n",
            "\n",
            "Epoch number:12 (0.0%)\tLoss:0.120\n",
            "Epoch number:12 (20.0%)\tLoss:0.129\n",
            "Epoch number:12 (40.0%)\tLoss:0.127\n",
            "Epoch number:12 (60.0%)\tLoss:0.112\n",
            "Epoch number:12 (80.0%)\tLoss:0.109\n",
            "Average loss:0.140\n",
            "IoU:0.887\n",
            "\n",
            "Epoch number:13 (0.0%)\tLoss:0.116\n",
            "Epoch number:13 (20.0%)\tLoss:0.116\n",
            "Epoch number:13 (40.0%)\tLoss:0.106\n",
            "Epoch number:13 (60.0%)\tLoss:0.099\n",
            "Epoch number:13 (80.0%)\tLoss:0.099\n",
            "Average loss:0.119\n",
            "IoU:0.902\n",
            "\n",
            "Epoch number:14 (0.0%)\tLoss:0.098\n",
            "Epoch number:14 (20.0%)\tLoss:0.095\n",
            "Epoch number:14 (40.0%)\tLoss:0.105\n",
            "Epoch number:14 (60.0%)\tLoss:0.090\n",
            "Epoch number:14 (80.0%)\tLoss:0.100\n",
            "Average loss:0.115\n",
            "IoU:0.893\n",
            "\n",
            "Epoch number:15 (0.0%)\tLoss:0.110\n",
            "Epoch number:15 (20.0%)\tLoss:0.087\n",
            "Epoch number:15 (40.0%)\tLoss:0.086\n",
            "Epoch number:15 (60.0%)\tLoss:0.083\n",
            "Epoch number:15 (80.0%)\tLoss:0.088\n",
            "Average loss:0.108\n",
            "IoU:0.891\n",
            "\n",
            "Epoch number:16 (0.0%)\tLoss:0.081\n",
            "Epoch number:16 (20.0%)\tLoss:0.083\n",
            "Epoch number:16 (40.0%)\tLoss:0.081\n",
            "Epoch number:16 (60.0%)\tLoss:0.085\n",
            "Epoch number:16 (80.0%)\tLoss:0.090\n",
            "Average loss:0.108\n",
            "IoU:0.900\n",
            "\n",
            "Epoch number:17 (0.0%)\tLoss:0.088\n",
            "Epoch number:17 (20.0%)\tLoss:0.076\n",
            "Epoch number:17 (40.0%)\tLoss:0.082\n",
            "Epoch number:17 (60.0%)\tLoss:0.073\n",
            "Epoch number:17 (80.0%)\tLoss:0.075\n",
            "Average loss:0.097\n",
            "IoU:0.902\n",
            "\n",
            "Epoch number:18 (0.0%)\tLoss:0.082\n",
            "Epoch number:18 (20.0%)\tLoss:0.071\n",
            "Epoch number:18 (40.0%)\tLoss:0.079\n",
            "Epoch number:18 (60.0%)\tLoss:0.069\n",
            "Epoch number:18 (80.0%)\tLoss:0.068\n",
            "Average loss:0.097\n",
            "IoU:0.892\n",
            "\n",
            "Epoch number:19 (0.0%)\tLoss:0.071\n",
            "Epoch number:19 (20.0%)\tLoss:0.065\n",
            "Epoch number:19 (40.0%)\tLoss:0.072\n",
            "Epoch number:19 (60.0%)\tLoss:0.072\n",
            "Epoch number:19 (80.0%)\tLoss:0.067\n",
            "Average loss:0.092\n",
            "IoU:0.902\n",
            "\n",
            "Epoch number:20 (0.0%)\tLoss:0.067\n",
            "Epoch number:20 (20.0%)\tLoss:0.067\n",
            "Epoch number:20 (40.0%)\tLoss:0.064\n",
            "Epoch number:20 (60.0%)\tLoss:0.063\n",
            "Epoch number:20 (80.0%)\tLoss:0.068\n",
            "Average loss:0.090\n",
            "IoU:0.897\n",
            "\n",
            "Epoch number:21 (0.0%)\tLoss:0.062\n",
            "Epoch number:21 (20.0%)\tLoss:0.061\n",
            "Epoch number:21 (40.0%)\tLoss:0.068\n",
            "Epoch number:21 (60.0%)\tLoss:0.064\n",
            "Epoch number:21 (80.0%)\tLoss:0.061\n",
            "Average loss:0.091\n",
            "IoU:0.897\n",
            "\n",
            "Epoch number:22 (0.0%)\tLoss:0.064\n",
            "Epoch number:22 (20.0%)\tLoss:0.057\n",
            "Epoch number:22 (40.0%)\tLoss:0.066\n",
            "Epoch number:22 (60.0%)\tLoss:0.056\n",
            "Epoch number:22 (80.0%)\tLoss:0.059\n",
            "Average loss:0.086\n",
            "IoU:0.911\n",
            "\n",
            "Epoch number:23 (0.0%)\tLoss:0.057\n",
            "Epoch number:23 (20.0%)\tLoss:0.056\n",
            "Epoch number:23 (40.0%)\tLoss:0.060\n",
            "Epoch number:23 (60.0%)\tLoss:0.062\n",
            "Epoch number:23 (80.0%)\tLoss:0.057\n",
            "Average loss:0.091\n",
            "IoU:0.892\n",
            "\n",
            "Epoch number:24 (0.0%)\tLoss:0.054\n",
            "Epoch number:24 (20.0%)\tLoss:0.061\n",
            "Epoch number:24 (40.0%)\tLoss:0.054\n",
            "Epoch number:24 (60.0%)\tLoss:0.054\n",
            "Epoch number:24 (80.0%)\tLoss:0.059\n",
            "Average loss:0.083\n",
            "IoU:0.916\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlWhUQcMyW8x"
      },
      "source": [
        "## Visualization\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPMTvh_3zByn"
      },
      "source": [
        "visualize output of your trained network on 5 data from validation dataset, and compare it with ground truth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk-OqCrJbggW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        },
        "outputId": "a63864ee-b692-4919-8361-7abc0462a034"
      },
      "source": [
        "batch = iter(val_dataloader).next()\n",
        "with torch.no_grad(): outputs = model(batch['image'].float())\n",
        "groundtruth = utils.make_grid(batch['mask'][:5] , nrow=5)\n",
        "out = utils.make_grid(255*(outputs[:5] >= 0.5) , nrow=5)\n",
        "_, (ax0, ax1) = plt.subplots(1, 2, figsize=(20, 20))\n",
        "ax0.set_title('outputs')\n",
        "ax1.set_title('Ground truth')\n",
        "ax0.imshow(np.transpose(out.numpy(), (1, 2, 0)), interpolation='nearest')\n",
        "ax1.imshow(np.transpose(groundtruth.numpy(), (1, 2, 0)), interpolation='nearest')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f1258932f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLThQ1kxzT0o"
      },
      "source": [
        "## Improve U-Net (bonus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3RHpUhyzm1Z"
      },
      "source": [
        "improve U-Net and compare accuracy and networks outputs with previous parts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9tj1WoVzUms"
      },
      "source": [
        "# We already have 91.6% accuracy :)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}